# ï¼/usr/bin/env python
# -*-coding:Utf-8 -*-
# Time:  16:25
# FileName: rerank
# Tools: PyCharm





class RerankRetriever:
    '''
    RerankRetriever (ç²¾æ’æ£€ç´¢å™¨)
        ä½¿ç”¨ LightWeightFlagLLMReranker è¿›è¡Œç»†ç²’åº¦åŒ¹é…
        è®¡ç®— query ä¸å®Œæ•´é—®ç­”å¯¹çš„è¯­ä¹‰ç›¸å…³æ€§
        ç²¾åº¦æ›´é«˜ä½†è€—æ—¶è¾ƒé•¿

    '''



    def __init__(self, model_name: str = rerank_path):
        """
        åˆå§‹åŒ–Rerankæ£€ç´¢å™¨
        :param model_name: Rerankæ¨¡å‹åç§°
        """
        logging.info(f"ğŸ› ï¸ æ­£åœ¨åŠ è½½Rerankæ¨¡å‹ : {model_name}...")
        self.model = FlagReranker(
            model_name,
            use_fp16=True,  #
            device=["0"],  # ä½¿ç”¨GPU
            cache_dir = "./rerank_cache",  # æ·»åŠ ç¼“å­˜ç›®å½•é¿å…å†…å­˜æ³„æ¼
            pool_processes = 0  # å…³é”®ï¼šç¦ç”¨å¤šè¿›ç¨‹
        )
        self.qa_texts = []
        logging.info("âœ… Rerankæ¨¡å‹åŠ è½½å®Œæˆ.....")

    def build_index(self, qa_pairs: List[Tuple[str, str]]):
        """
        å‡†å¤‡é—®ç­”å¯¹æ•°æ®
        :param qa_pairs: é—®ç­”å¯¹åˆ—è¡¨
        """
        if not qa_pairs:
            raise ValueError("çŸ¥è¯†åº“ä¸èƒ½ä¸ºç©ºï¼")

        logging.info(f"ğŸ“‹ å‡†å¤‡ {len(qa_pairs)} æ¡é—®ç­”å¯¹ç”¨äºRerank...")
        # å°†é—®ç­”å¯¹è½¬æ¢ä¸ºæ–‡æœ¬ï¼š"é—®é¢˜ [SEP] ç­”æ¡ˆ"
        self.qa_texts = [f"{q} [SEP] {a}" for q, a in qa_pairs]

        logging.info("âœ… æ•°æ®å‡†å¤‡å®Œæˆ.....")
        print(f"âœ… rerankæ•°æ®å‡†å¤‡å®Œæˆ....self.qa_textsæ•°æ®å†…å®¹ï¼š{self.qa_texts}")



    def search(self, query: str, top_k: int = 5, batch_size: int = 32) -> List[Tuple[float, Tuple[str, str]]]:
        """
        æ‰§è¡ŒRerankæ£€ç´¢
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param top_k: è¿”å›çš„ç»“æœæ•°é‡
        :param batch_size: æ‰¹å¤„ç†å¤§å°
        :return: åŒ…å«(åˆ†æ•°, (é—®é¢˜, ç­”æ¡ˆ))çš„åˆ—è¡¨
        """
        if not self.qa_texts:
            raise RuntimeError("è¯·å…ˆè°ƒç”¨ build_index å‡†å¤‡æ•°æ®ï¼")

        logging.info(f"ğŸ” æ­£åœ¨å¯¹ {len(self.qa_texts)} æ¡å€™é€‰è¿›è¡ŒRerank...")
        scores = []
        total = len(self.qa_texts)

        # æ‰¹é‡å¤„ç†ä»¥æé«˜æ•ˆç‡
        for i in tqdm(range(0, total, batch_size)):
            batch_texts = self.qa_texts[i:i + batch_size]
            # å‡†å¤‡æŸ¥è¯¢-æ–‡æœ¬å¯¹
            pairs = [(query, text) for text in batch_texts]

            # # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
            # batch_scores = self.model.compute_score(
            #     pairs,
            #     cutoff_layers=[28],  # ä½¿ç”¨é¡¶å±‚è¡¨ç¤º
            #     compress_ratio=1.5,  # å‹ç¼©ç‡å¹³è¡¡ç²¾åº¦/é€Ÿåº¦
            #     compress_layer=[24, 40]  # å‹ç¼©å±‚è®¾ç½®
            # )
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
            batch_scores = self.model.compute_score(
                pairs,
                normalize=True
            )
            scores.extend(batch_scores)

        # è·å–TopKç»“æœ
        '''
        np.argsort(scores)ï¼šè¾“å‡º ç´¢å¼•æ ¹æ® scoresçš„å‡åºæ’åˆ—
        [::-1]:åè½¬æ’åºï¼Œ
        '''
        indices = np.argsort(scores)[::-1][:top_k]
        results = [(float(scores[i]), self._split_qa(self.qa_texts[i])) for i in indices]



        return sorted(results, key=lambda x: x[0], reverse=True)

    def _split_qa(self, text: str) -> Tuple[str, str]:
        """å°†ç»„åˆæ–‡æœ¬åˆ†å‰²å›é—®ç­”å¯¹"""
        if " [SEP] " in text:
            return tuple(text.split(" [SEP] ", 1))
        return text, ""

    def close(self):
        """å®‰å…¨å…³é—­èµ„æº"""
        try:
            # æ‰‹åŠ¨é‡Šæ”¾æ¨¡å‹èµ„æº
            if hasattr(self.model, "model"):
                del self.model.model
            if hasattr(self.model, "tokenizer"):
                del self.model.tokenizer
            # æ˜¾å¼åƒåœ¾å›æ”¶
            gc.collect()
        except:
            pass
